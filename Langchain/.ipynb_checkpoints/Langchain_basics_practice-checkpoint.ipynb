{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a7aec7-6727-4c92-b183-fff7eca77eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.14-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (2.1)\n",
      "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "Downloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.2.10-py3-none-any.whl (326 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.0 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.14-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Installing collected packages: pydantic-core, orjson, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed langchain-0.3.14 langchain-core-0.3.29 langchain-text-splitters-0.3.5 langsmith-0.2.10 orjson-3.10.14 pydantic-2.10.4 pydantic-core-2.27.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e582b3c-862b-4049-88a3-a80fb5b39dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_openai) (0.3.29)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n",
      "  Downloading openai-1.59.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_openai) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain_openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "Downloading openai-1.59.5-py3-none-any.whl (454 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/883.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/883.8 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/883.8 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/883.8 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/883.8 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/883.8 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/883.8 kB ? eta -:--:--\n",
      "   ---------------------- --------------- 524.3/883.8 kB 289.3 kB/s eta 0:00:02\n",
      "   ---------------------- --------------- 524.3/883.8 kB 289.3 kB/s eta 0:00:02\n",
      "   ---------------------- --------------- 524.3/883.8 kB 289.3 kB/s eta 0:00:02\n",
      "   --------------------------------- ---- 786.4/883.8 kB 325.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 883.8/883.8 kB 343.1 kB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken, openai, langchain_openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.54.4\n",
      "    Uninstalling openai-1.54.4:\n",
      "      Successfully uninstalled openai-1.54.4\n",
      "Successfully installed langchain_openai-0.2.14 openai-1.59.5 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9547100-7620-474a-aa3f-f02c55dddc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d330d38-c34e-4ac9-943f-e3862e8e99fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_google_genai\n",
      "  Downloading langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_google_genai) (0.8.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_google_genai) (0.3.29)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_google_genai) (2.10.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.157.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.37.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.25.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.25.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (8.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (2.27.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (1.0.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_google_genai) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.2.3)\n",
      "Downloading langchain_google_genai-2.0.8-py3-none-any.whl (41 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: filetype, langchain_google_genai\n",
      "Successfully installed filetype-1.2.0 langchain_google_genai-2.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f3ab8-8a0a-4991-935d-faafffc04476",
   "metadata": {},
   "source": [
    "# Step 1 - Models (LLM and ChatLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04195291-f2c3-4767-a356-7e695e7efead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc97a547-8d3d-40ea-aa83-7afcb464e11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Covariance is a measure of the relationship between two random variables.  Specifically, it quantifies how much two variables change together.  A positive covariance indicates that the variables tend to move in the same direction: when one increases, the other tends to increase as well. A negative covariance means they tend to move in opposite directions.  A covariance of zero suggests there's no linear relationship between the variables.\\n\\nHere's a breakdown:\\n\\n* **Positive Covariance:**  As X increases, Y tends to increase.  Example: Height and weight – taller people tend to weigh more.\\n\\n* **Negative Covariance:** As X increases, Y tends to decrease. Example: Hours spent watching TV and exam scores – more TV time might correlate with lower scores.\\n\\n* **Zero Covariance:** There's no apparent linear relationship between X and Y.  This doesn't necessarily mean there's *no* relationship at all; it just means there's no *linear* relationship.  A non-linear relationship could still exist.\\n\\n**Important Considerations:**\\n\\n* **Scale Dependence:** The magnitude of the covariance is highly dependent on the scales of the variables.  A large covariance doesn't necessarily mean a strong relationship if the variables are measured on very large scales.  This is why correlation is often preferred.\\n\\n* **Correlation vs. Covariance:**  Correlation is a *normalized* version of covariance. It ranges from -1 to +1, making it easier to interpret the strength of the relationship regardless of the scales of the variables.  Correlation essentially tells you the direction and strength of the linear relationship, while covariance only tells you the direction.\\n\\n* **Linear Relationship:** Covariance only measures *linear* relationships.  If the relationship between the variables is non-linear (e.g., a U-shaped curve), the covariance might be close to zero even if a strong relationship exists.\\n\\n\\nIn summary, covariance is a useful tool for understanding the relationship between two variables, but it's crucial to interpret it carefully and consider its limitations, especially in comparison to correlation.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-619001f6-7e2c-42ac-a48c-37fe91838921-0' usage_metadata={'input_tokens': 7, 'output_tokens': 428, 'total_tokens': 435, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "f = open(r\"C:\\Users\\DeLL\\Documents\\Data Science\\Gen AI\\Building  conversational chat bot and intro to Gemini\\Google API Key.txt\")\n",
    "key = f.read().strip()\n",
    "chat_model = ChatGoogleGenerativeAI(api_key = key, model = 'gemini-1.5-flash')\n",
    "prompt = 'what is covarience?'\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03521e-d217-429e-aefb-915727a15ba8",
   "metadata": {},
   "source": [
    "# Prompts - Can be 'string' or 'Chat Messages'\n",
    "# Template - Logic 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f032da0-5c50-4143-a8b6-49012fc2512b",
   "metadata": {},
   "source": [
    "### we have first saw how to change the model name - that is we can eitehr take Openai or google ai, cohere, anthropic etc.,\n",
    "### now we will se how to write a template which will also be same for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef4a843-32f6-4260-baf2-2167bfb887ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    ('system', 'you are a helpful AI tutor with expertise in data science and artificial intelligence.'),\n",
    "    ('human', 'What is {topic}?')\n",
    "])\n",
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449d3f6-8fd7-47e5-ad51-118bedf944e7",
   "metadata": {},
   "source": [
    "We can merge the model and the template part by connecting with a chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222cd398-f5ab-43d1-bb25-b25969adde28",
   "metadata": {},
   "source": [
    "# Chains \n",
    "### Chains allow us to link the output of one LLM call as the input of another call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aecbb942-00f0-4483-804a-3fb6a6d2d827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"NLP, or Natural Language Processing, is a branch of artificial intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language.  It bridges the gap between human communication and computer understanding.  Instead of dealing with numbers and symbols like traditional computing, NLP deals with the complexities of human language, including its nuances, ambiguities, and context.\\n\\nHere's a breakdown of what that entails:\\n\\n* **Understanding:** NLP algorithms aim to extract meaning from text or speech. This includes tasks like:\\n    * **Tokenization:** Breaking down text into individual words or units.\\n    * **Part-of-speech tagging:** Identifying the grammatical role of each word (noun, verb, adjective, etc.).\\n    * **Named entity recognition (NER):** Identifying and classifying named entities like people, organizations, and locations.\\n    * **Sentiment analysis:** Determining the emotional tone of a piece of text (positive, negative, neutral).\\n    * **Topic modeling:** Discovering underlying themes and topics in a collection of documents.\\n\\n* **Interpreting:**  This involves going beyond simple understanding to grasp the intent, context, and meaning behind the language.  This often requires sophisticated techniques that consider things like:\\n    * **Word sense disambiguation:** Determining the correct meaning of a word based on its context.\\n    * **Relationship extraction:** Identifying relationships between entities mentioned in text.\\n    * **Coreference resolution:** Identifying when different words or phrases refer to the same entity.\\n\\n* **Generating:** NLP also enables computers to create human-like text. This includes tasks like:\\n    * **Machine translation:** Translating text from one language to another.\\n    * **Text summarization:** Creating concise summaries of longer texts.\\n    * **Chatbots and conversational AI:** Building systems that can engage in natural conversations with humans.\\n    * **Text generation:** Creating new text based on a given prompt or context.\\n\\n\\nNLP is used in a wide range of applications, including:\\n\\n* **Search engines:** Understanding user queries and returning relevant results.\\n* **Chatbots and virtual assistants:** Providing automated customer service and assistance.\\n* **Machine translation:** Translating text and speech between different languages.\\n* **Social media monitoring:** Analyzing social media data to understand public opinion.\\n* **Medical diagnosis:** Assisting doctors in analyzing patient records and medical literature.\\n* **Spam detection:** Identifying and filtering spam emails.\\n\\n\\nIn short, NLP is a powerful field that is constantly evolving and finding new applications as the technology improves.  It's a fascinating area of study that combines linguistics, computer science, and artificial intelligence.  Do you have any specific aspects of NLP you'd like to explore further?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-65968c57-b72f-43fc-ad0f-7890ac45a084-0', usage_metadata={'input_tokens': 20, 'output_tokens': 560, 'total_tokens': 580, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | chat_model\n",
    "\n",
    "input = {'topic' : 'NLP'}\n",
    "\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ab5f24-ff2c-4167-acdc-5def80689f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP, or Natural Language Processing, is a branch of artificial intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language.  It bridges the gap between human communication and computer understanding.  Instead of working with numbers and symbols like traditional computer programs, NLP deals with the complexities of human language, including its nuances, ambiguities, and contextual variations.\n",
      "\n",
      "Here's a breakdown of key aspects:\n",
      "\n",
      "* **Understanding Human Language:** This involves tasks like:\n",
      "    * **Tokenization:** Breaking down text into individual words or sub-words (tokens).\n",
      "    * **Part-of-Speech Tagging:** Identifying the grammatical role of each word (noun, verb, adjective, etc.).\n",
      "    * **Named Entity Recognition (NER):** Identifying and classifying named entities like people, organizations, locations, etc.\n",
      "    * **Sentiment Analysis:** Determining the emotional tone of a text (positive, negative, neutral).\n",
      "    * **Word Sense Disambiguation:** Determining the correct meaning of a word based on context.\n",
      "\n",
      "* **Interpreting Meaning:** This goes beyond simple grammatical analysis and involves understanding the deeper meaning and intent behind the text.  This is often a more challenging aspect and involves techniques like:\n",
      "    * **Semantic Analysis:** Understanding the meaning of words and sentences.\n",
      "    * **Discourse Analysis:** Understanding how sentences relate to each other in a larger text.\n",
      "    * **Pragmatics:** Understanding the implied meaning and context of language.\n",
      "\n",
      "* **Generating Human Language:** This involves creating text that is grammatically correct and semantically meaningful.  Examples include:\n",
      "    * **Machine Translation:** Translating text from one language to another.\n",
      "    * **Text Summarization:** Generating concise summaries of longer texts.\n",
      "    * **Chatbots and Conversational AI:** Creating systems that can engage in natural conversations with humans.\n",
      "    * **Text Generation:** Creating new text based on a given prompt or context (e.g., writing stories, poems, or articles).\n",
      "\n",
      "\n",
      "NLP relies on a variety of techniques, including:\n",
      "\n",
      "* **Rule-based systems:**  Using handcrafted rules to process language.\n",
      "* **Statistical methods:** Using statistical models to learn patterns in language data.\n",
      "* **Machine learning (ML):** Training algorithms on large datasets to learn how to process language.\n",
      "* **Deep learning (DL):** Using deep neural networks to process language, often achieving state-of-the-art results.\n",
      "\n",
      "\n",
      "NLP has numerous applications across various fields, including:\n",
      "\n",
      "* **Customer service (chatbots)**\n",
      "* **Healthcare (medical record analysis)**\n",
      "* **Finance (fraud detection)**\n",
      "* **Education (language learning tools)**\n",
      "* **Marketing (sentiment analysis of customer reviews)**\n",
      "* **Search engines**\n",
      "\n",
      "\n",
      "Understanding NLP is crucial for anyone working in data science or artificial intelligence, as it's a rapidly evolving field with significant impact on numerous aspects of our lives.  Do you have any specific areas within NLP you'd like to explore further?  Perhaps you're interested in a particular application or technique?\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template | chat_model\n",
    "\n",
    "input = {'topic' : 'NLP'}\n",
    "\n",
    "print(chain.invoke(input).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74906d9-8c97-47b8-be98-f37191aa53d5",
   "metadata": {},
   "source": [
    "**Let us use the output parsing as well**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2647e-c8a2-416b-88da-b6c61b8b7ab4",
   "metadata": {},
   "source": [
    "# Output Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23bbd141-023d-44d6-9c4a-963002cf674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ef175-9bf7-40dc-bf85-04ba22342f9a",
   "metadata": {},
   "source": [
    "# Modifying the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a00554bc-c17c-4507-80b6-94465007638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP, or Natural Language Processing, is a branch of artificial intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language.  It bridges the gap between human communication and computer understanding.  Instead of dealing with numbers and symbols like traditional computer programs, NLP works with the complexities of human language, including its nuances, ambiguities, and context.\n",
      "\n",
      "Here's a breakdown of key aspects:\n",
      "\n",
      "* **Understanding Human Language:** This involves tasks like:\n",
      "    * **Tokenization:** Breaking down text into individual words or units (tokens).\n",
      "    * **Part-of-Speech Tagging:** Identifying the grammatical role of each word (noun, verb, adjective, etc.).\n",
      "    * **Named Entity Recognition (NER):** Identifying and classifying named entities like people, organizations, locations, etc.\n",
      "    * **Sentiment Analysis:** Determining the emotional tone of a text (positive, negative, neutral).\n",
      "    * **Word Sense Disambiguation:** Determining the correct meaning of a word based on its context.\n",
      "\n",
      "* **Interpreting Meaning:** This goes beyond simply understanding individual words and involves:\n",
      "    * **Relationship Extraction:** Identifying relationships between entities in a text.\n",
      "    * **Text Summarization:** Condensing large amounts of text into shorter summaries.\n",
      "    * **Question Answering:** Answering questions based on provided text.\n",
      "    * **Topic Modeling:** Discovering underlying topics in a collection of documents.\n",
      "\n",
      "* **Generating Human Language:** This includes tasks like:\n",
      "    * **Machine Translation:** Translating text from one language to another.\n",
      "    * **Text Generation:** Creating new text, such as stories, articles, or code.\n",
      "    * **Chatbots and Conversational AI:** Building systems that can engage in natural conversations with humans.\n",
      "\n",
      "**Why is NLP important?**\n",
      "\n",
      "NLP is crucial because it allows computers to interact with humans in a more natural and intuitive way.  Its applications are vast and growing rapidly, impacting fields like:\n",
      "\n",
      "* **Customer service:** Chatbots and virtual assistants.\n",
      "* **Healthcare:** Analyzing medical records and research papers.\n",
      "* **Finance:** Sentiment analysis of market news and social media.\n",
      "* **Education:** Automated essay grading and language learning tools.\n",
      "* **Search engines:** Improving search relevance and understanding user queries.\n",
      "\n",
      "In short, NLP is a powerful tool that's transforming the way we interact with computers and the world around us.  It's a constantly evolving field with ongoing research pushing the boundaries of what's possible in terms of computer understanding and generation of human language.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template | chat_model | output_parser\n",
    "input = {'topic' : 'NLP'}\n",
    "print(chain.invoke(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89649c-3817-4b24-99c0-13f1e35fd66b",
   "metadata": {},
   "source": [
    "# Example - Create an AI tutor APP that uses prompts and Chat internally to given Python implementation tutorial for Data science topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38cb81b6-937a-4b1f-ac9d-5658274c71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GoogleAI chat Model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Set the CHatGoogleGenerativeAI key and initialize the model\n",
    "chat_model = ChatGoogleGenerativeAI(api_key = key, model = 'gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7adb028-b73c-421b-b0c7-99c8e68a38d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic_name'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a friendly AI Tutor with expertise in Data Science and AI \\nwho tells step by step Python implementation for topics asked by user.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic_name'], input_types={}, partial_variables={}, template='Tell me a python implementation for {topic_name}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the Template\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# Construct system prompt\n",
    "system_prompt = SystemMessagePromptTemplate.from_template('''You are a friendly AI Tutor with expertise in Data Science and AI \n",
    "who tells step by step Python implementation for topics asked by user.''')\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template('Tell me a python implementation for {topic_name}')\n",
    "\n",
    "chat_template = ChatPromptTemplate([system_prompt, human_prompt])\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db2533b-1d70-4c96-abd1-78e18381dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd part - Output Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6c918c-2f43-437d-b210-a918b8eda09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's build a Logistic Regression model in Python step-by-step. We'll use the popular `scikit-learn` library.  This example will cover both training and prediction.\n",
      "\n",
      "**Step 1: Import necessary libraries**\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "```\n",
      "\n",
      "This imports NumPy for numerical operations, Pandas for data manipulation, `train_test_split` for splitting data, `LogisticRegression` for the model, and some metrics for evaluation.\n",
      "\n",
      "**Step 2: Load and prepare the data**\n",
      "\n",
      "For this example, I'll use a simple synthetic dataset.  You can replace this with your own data by loading it using Pandas' `read_csv` function.\n",
      "\n",
      "```python\n",
      "# Sample data (replace with your own data loading)\n",
      "np.random.seed(42)  # for reproducibility\n",
      "X = np.random.rand(100, 2) * 10  # 100 samples, 2 features\n",
      "y = np.array([1 if x[0] + x[1] > 10 else 0 for x in X])\n",
      "\n",
      "# Convert to pandas DataFrame for easier handling (optional)\n",
      "df = pd.DataFrame(X, columns=['feature1', 'feature2'])\n",
      "df['target'] = y\n",
      "```\n",
      "\n",
      "This creates a dataset with two features and a binary target variable (0 or 1).  The target is determined by a simple linear combination of the features.\n",
      "\n",
      "**Step 3: Split data into training and testing sets**\n",
      "\n",
      "```python\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "```\n",
      "\n",
      "This splits the data into 80% for training and 20% for testing.  `random_state` ensures consistent splits for reproducibility.\n",
      "\n",
      "**Step 4: Train the Logistic Regression model**\n",
      "\n",
      "```python\n",
      "model = LogisticRegression()\n",
      "model.fit(X_train, y_train)\n",
      "```\n",
      "\n",
      "This creates a LogisticRegression object and trains it using the training data.\n",
      "\n",
      "**Step 5: Make predictions on the test set**\n",
      "\n",
      "```python\n",
      "y_pred = model.predict(X_test)\n",
      "```\n",
      "\n",
      "This uses the trained model to predict the target variable for the test set.\n",
      "\n",
      "**Step 6: Evaluate the model**\n",
      "\n",
      "```python\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "conf_matrix = confusion_matrix(y_test, y_pred)\n",
      "class_report = classification_report(y_test, y_pred)\n",
      "\n",
      "print(f\"Accuracy: {accuracy}\")\n",
      "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
      "print(f\"Classification Report:\\n{class_report}\")\n",
      "```\n",
      "\n",
      "This evaluates the model's performance using accuracy, confusion matrix, and classification report, which includes precision, recall, F1-score.\n",
      "\n",
      "**Complete Code:**\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "\n",
      "# Sample data (replace with your own data loading)\n",
      "np.random.seed(42)\n",
      "X = np.random.rand(100, 2) * 10\n",
      "y = np.array([1 if x[0] + x[1] > 10 else 0 for x in X])\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "model = LogisticRegression()\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "conf_matrix = confusion_matrix(y_test, y_pred)\n",
      "class_report = classification_report(y_test, y_pred)\n",
      "\n",
      "print(f\"Accuracy: {accuracy}\")\n",
      "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
      "print(f\"Classification Report:\\n{class_report}\")\n",
      "```\n",
      "\n",
      "Remember to replace the sample data with your own dataset.  You might need to preprocess your data (handle missing values, scale features, etc.) before training the model, depending on your data's characteristics.  Let me know if you'd like to explore any of these aspects further!\n"
     ]
    }
   ],
   "source": [
    "# 4th part - Chain\n",
    "chain = chat_template | chat_model | output_parser\n",
    "\n",
    "input = {'topic_name' : 'Logistic Regression'}\n",
    "\n",
    "response = chain.invoke(input)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23785d6f-6638-40ec-9bc4-5ba8d5f136af",
   "metadata": {},
   "source": [
    "# Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72124381-d0bf-4f38-b81b-6614179658e5",
   "metadata": {},
   "source": [
    "## CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f209ff2-1ad3-48f6-94b4-53f9ed07c5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "csv_output_parser = CommaSeparatedListOutputParser()\n",
    "csv_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192a8906-32f0-4ea8-ba4c-be8404e74c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input = \"Python, DA, SQL, ML, DL, AI\"\n",
    "type(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51faba7c-32f0-4b89-9bc4-af2c9b50949e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'DA', 'SQL', 'ML', 'DL', 'AI']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_output_parser.parse(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60d70c87-846f-46aa-81bc-c48e4d7028bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['dish_name', 'output_format_instructions'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output_format_instructions'], input_types={}, partial_variables={}, template=' You are a helpful AI chef Assistant. Given a dish name by user, \\nyou can provide the ingredients to prepare the dish. Output Format Instructions : {output_format_instructions} '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dish_name'], input_types={}, partial_variables={}, template='Give me the ingredients to prepare {dish_name}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\"\"\" You are a helpful AI chef Assistant. Given a dish name by user, \n",
    "you can provide the ingredients to prepare the dish. Output Format Instructions : {output_format_instructions} \"\"\")\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template('Give me the ingredients to prepare {dish_name}')\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98ee8bee-36be-436b-a630-5e2b379ecb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mutton', 'Basmati rice', 'Onion', 'Ginger', 'Garlic', 'Green chilies', 'Yogurt', 'Spices (cinnamon', 'cloves', 'cardamom', 'nutmeg', 'peppercorns)', 'Bay leaves', 'Saffron', 'Ghee or oil', 'Salt', 'Fried onions (optional)', 'Fresh cilantro (optional)', 'Mint leaves (optional)']\n"
     ]
    }
   ],
   "source": [
    "chain = chat_template | chat_model | csv_output_parser\n",
    "input = {'output_format_instructions' : csv_output_parser.get_format_instructions(), 'dish_name' : 'mutton biryani'}\n",
    "response = chain.invoke(input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66cf7c1-8192-4664-b9da-b74d1a141277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bcf4635-1917-4800-8107-5958d5239a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "csv_output_parser = CommaSeparatedListOutputParser()\n",
    "csv_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bc901e1-3be6-4e91-849a-fba27b99925b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['output_format_instructions'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output_format_instructions'], input_types={}, partial_variables={}, template='You are a helpful instructor who solves the problems or answers the\\n                                                        questions in simple and clear manner. Output format instructions : \\n                                                        {output_format_instructions}. lets think step by step'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='give me the top 10 countries by GDP'), additional_kwargs={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template('''You are a helpful instructor who solves the problems or answers the\n",
    "                                                        questions in simple and clear manner. Output format instructions : \n",
    "                                                        {output_format_instructions}. lets think step by step''')\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template('give me the top 10 countries by GDP')\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96edcac8-d70a-40d4-8154-4b257875577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States', 'China', 'Japan', 'Germany', 'India', 'United Kingdom', 'France', 'Canada', 'Italy', 'Brazil']\n"
     ]
    }
   ],
   "source": [
    "chain = chat_template | chat_model | csv_output_parser\n",
    "input = {'output_format_instructions' : csv_output_parser.get_format_instructions()}\n",
    "print(chain.invoke(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b20fc-e164-4446-8309-0a62ac70ca11",
   "metadata": {},
   "source": [
    "## DateTime Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e67143c8-bc60-41bb-aa12-2928d693e9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf0e27e8-f913-477e-97fa-1fca863e844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 0487-12-03T18:17:36.697390Z, 1309-10-22T06:56:37.922020Z, 1383-03-11T10:37:14.205742Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "output_parser = DatetimeOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67020974-6ed0-4fba-8340-870f15639d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['output_format_instructions'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output_format_instructions'], input_types={}, partial_variables={}, template='You are a helpful instructor who solves the problems or answers the\\n                                                        questions in simple and clear manner. Output format instructions : \\n                                                        {output_format_instructions}. lets think step by step'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='When was the first US president elected?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template('''You are a helpful instructor who solves the problems or answers the\n",
    "                                                        questions in simple and clear manner. Output format instructions : \n",
    "                                                        {output_format_instructions}. lets think step by step''')\n",
    "human_prompt = HumanMessagePromptTemplate.from_template('When was the first US president elected?')\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12d8cb60-ddc2-4397-9cd9-0bc03d80b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789-04-06 00:00:00\n"
     ]
    }
   ],
   "source": [
    "chain = chat_template | chat_model | output_parser\n",
    "user_input = {'output_format_instructions' : output_parser.get_format_instructions()}\n",
    "print(chain.invoke(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0cd75-6238-40da-98b3-54e6b12cfff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
